{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *App Scraping*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "pip install google-play-scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from google_play_scraper import Sort, reviews, app\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "TAG_RE = re.compile(r'<[^>]+>')\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    text = TAG_RE.sub('', text)  # Remove HTML tags\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces, newlines, and tabs\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code uses the downloaded scraper to take app descriptions, number of downloads, and user reviews for 17 different dating apps from the Google Play Store."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ***Tinder***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "result_tinder, continuation_token = reviews(\n",
    "    'com.tinder',\n",
    "    lang='en', # English reviews\n",
    "    country='us', # reviews from US\n",
    "    sort=Sort.NEWEST, # return newest reviews\n",
    "    count=200, # return 200 reviews\n",
    ")\n",
    "\n",
    "# If you pass `continuation_token` as an argument to the reviews function at this point,\n",
    "# it will crawl the items after 3 review items.\n",
    "\n",
    "time.sleep(0.1) # pause before next request\n",
    "\n",
    "\n",
    "result_tinder, _ = reviews(\n",
    "    'com.tinder',\n",
    "    continuation_token=continuation_token # avoids returning duplicate reviews\n",
    ")\n",
    "\n",
    "result_tinder_df = pd.DataFrame(result_tinder)\n",
    "result_tinder_df = result_tinder_df.drop(['reviewId', 'userImage', 'reviewCreatedVersion'], axis=1)\n",
    "result_tinder_df['App'] = 'Tinder'\n",
    "\n",
    "time.sleep(0.1) # pause before fetching app description\n",
    "\n",
    "result_tinder_des = app(\n",
    "    'com.tinder',\n",
    "    lang='en', # defaults to 'en'\n",
    "    country='us' # defaults to 'us'\n",
    ")\n",
    "\n",
    "tinder_description = clean_text(result_tinder_des['description'])\n",
    "tinder_installs = result_tinder_des[\"realInstalls\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Hinge***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "result_hinge, continuation_token = reviews(\n",
    "    'co.hinge.app',\n",
    "    lang='en', # English reviews\n",
    "    country='us', # reviews from US\n",
    "    sort=Sort.NEWEST, # return newest reviews\n",
    "    count=200, # return 200 reviews\n",
    "    #filter_score_with=5 # we can filter for certain scores\n",
    ")\n",
    "\n",
    "# If you pass `continuation_token` as an argument to the reviews function at this point,\n",
    "# it will crawl the items after 3 review items.\n",
    "\n",
    "time.sleep(0.1) # pause before next request\n",
    "\n",
    "result_hinge, _ = reviews(\n",
    "    'co.hinge.app',\n",
    "    continuation_token=continuation_token # avoids returning duplicate reviews\n",
    ")\n",
    "\n",
    "result_hinge_df = pd.DataFrame(result_hinge)\n",
    "result_hinge_df = result_hinge_df.drop(['reviewId', 'userImage', 'reviewCreatedVersion'], axis=1) # remove columns\n",
    "result_hinge_df['App'] = 'Hinge' # create new column with app name\n",
    "\n",
    "time.sleep(0.1) # pause before fetching app description\n",
    "\n",
    "# create a new column with description\n",
    "result_hinge_des = app(\n",
    "    'co.hinge.app',\n",
    "    lang='en', # defaults to 'en'\n",
    "    country='us' # defaults to 'us'\n",
    ")\n",
    "\n",
    "hinge_description = clean_text(result_hinge_des['description'])\n",
    "hinge_installs = result_tinder_des[\"realInstalls\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Bumble***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "result_bumble, continuation_token = reviews(\n",
    "    'com.bumble.app',\n",
    "    lang='en', # English reviews\n",
    "    country='us', # reviews from US\n",
    "    sort=Sort.NEWEST, # return newest reviews\n",
    "    count=200, # return 200 reviews\n",
    "    #filter_score_with=5 # we can filter for certain scores\n",
    ")\n",
    "\n",
    "# If you pass `continuation_token` as an argument to the reviews function at this point,\n",
    "# it will crawl the items after 3 review items.\n",
    "\n",
    "time.sleep(0.1) # pause before next request\n",
    "\n",
    "result_bumble, _ = reviews(\n",
    "    'com.bumble.app',\n",
    "    continuation_token=continuation_token # avoids returning duplicate reviews\n",
    ")\n",
    "\n",
    "result_bumble_df = pd.DataFrame(result_bumble)\n",
    "result_bumble_df = result_bumble_df.drop(['reviewId', 'userImage', 'reviewCreatedVersion'], axis=1) # remove columns\n",
    "result_bumble_df['App'] = 'Bumble' # create new column with app name\n",
    "\n",
    "time.sleep(0.1) # pause before fetching app description\n",
    "\n",
    "# create a new column with description\n",
    "result_bumble_des = app(\n",
    "    'com.bumble.app',\n",
    "    lang='en', # defaults to 'en'\n",
    "    country='us' # defaults to 'us'\n",
    ")\n",
    "\n",
    "bumble_description = clean_text(result_bumble_des['description'])\n",
    "bumble_installs = result_bumble_des['realInstalls']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Her***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "result_her, continuation_token = reviews(\n",
    "    'com.weareher.her',\n",
    "    lang='en', # English reviews\n",
    "    country='us', # reviews from US\n",
    "    sort=Sort.NEWEST, # return newest reviews\n",
    "    count=200, # return 200 reviews\n",
    ")\n",
    "\n",
    "# If you pass `continuation_token` as an argument to the reviews function at this point,\n",
    "# it will crawl the items after 3 review items.\n",
    "\n",
    "time.sleep(0.1) # pause before next request\n",
    "\n",
    "result_her, _ = reviews(\n",
    "    'com.weareher.her',\n",
    "    continuation_token=continuation_token # avoids returning duplicate reviews\n",
    ")\n",
    "\n",
    "\n",
    "result_her_df = pd.DataFrame(result_her) # make into df\n",
    "result_her_df = result_her_df.drop(['reviewId', 'userImage', 'reviewCreatedVersion'], axis=1) # remove columns\n",
    "result_her_df['App'] = 'Her' # create new column with app name\n",
    "\n",
    "time.sleep(0.1) # pause before fetching app description\n",
    "\n",
    "# create a new column with description\n",
    "result_her_des = app(\n",
    "    'com.weareher.her',\n",
    "    lang='en', # defaults to 'en'\n",
    "    country='us' # defaults to 'us'\n",
    ")\n",
    "\n",
    "her_description = clean_text(result_her_des['description'])\n",
    "her_installs = result_her_des['realInstalls']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Zoe***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "result_zoe, continuation_token = reviews(\n",
    "    'com.surgeapp.zoe',\n",
    "    lang='en', # English reviews\n",
    "    country='us', # reviews from US\n",
    "    sort=Sort.NEWEST, # return newest reviews\n",
    "    count=200, # return 200 reviews\n",
    ")\n",
    "\n",
    "# If you pass `continuation_token` as an argument to the reviews function at this point,\n",
    "# it will crawl the items after 3 review items.\n",
    "\n",
    "time.sleep(0.1) # pause before next request\n",
    "\n",
    "result_zoe, _ = reviews(\n",
    "    'com.surgeapp.zoe',\n",
    "    continuation_token=continuation_token # avoids returning duplicate reviews\n",
    ")\n",
    "\n",
    "result_zoe_df = pd.DataFrame(result_zoe) # make into df\n",
    "result_zoe_df = result_zoe_df.drop(['reviewId', 'userImage', 'reviewCreatedVersion'], axis=1) # remove columns\n",
    "result_zoe_df['App'] = 'Zoe' # create new column with app name\n",
    "\n",
    "time.sleep(0.1) # pause before fetching app description\n",
    "\n",
    "# create a new column with description\n",
    "result_zoe_des = app(\n",
    "    'com.surgeapp.zoe',\n",
    "    lang='en', # defaults to 'en'\n",
    "    country='us' # defaults to 'us'\n",
    ")\n",
    "\n",
    "zoe_description = clean_text(result_zoe_des['description'])\n",
    "zoe_installs = result_zoe_des['realInstalls']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Grindr***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "result_grindr, continuation_token = reviews(\n",
    "    'com.grindrapp.android',\n",
    "    lang='en', # English reviews\n",
    "    country='us', # reviews from US\n",
    "    sort=Sort.NEWEST, # return newest reviews\n",
    "    count=200, # return 200 reviews\n",
    ")\n",
    "\n",
    "# If you pass `continuation_token` as an argument to the reviews function at this point,\n",
    "# it will crawl the items after 3 review items.\n",
    "\n",
    "time.sleep(0.1) # pause before next request\n",
    "\n",
    "result_grindr, _ = reviews(\n",
    "    'com.grindrapp.android',\n",
    "    continuation_token=continuation_token # avoids returning duplicate reviews\n",
    ")\n",
    "\n",
    "result_grindr_df = pd.DataFrame(result_grindr) # make into df\n",
    "result_grindr_df = result_grindr_df.drop(['reviewId', 'userImage', 'reviewCreatedVersion'], axis=1) # remove columns\n",
    "result_grindr_df['App'] = 'Grindr' # create new column with app name\n",
    "\n",
    "time.sleep(0.1) # pause before fetching app description\n",
    "\n",
    "# create a new column with description\n",
    "result_grindr_des = app(\n",
    "    'com.grindrapp.android',\n",
    "    lang='en', # defaults to 'en'\n",
    "    country='us' # defaults to 'us'\n",
    ")\n",
    "\n",
    "grindr_description = clean_text(result_grindr_des['description'])\n",
    "grindr_installs = result_grindr_des['realInstalls']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***SCRUFF***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "result_scruff, continuation_token = reviews(\n",
    "    'com.appspot.scruffapp',\n",
    "    lang='en', # English reviews\n",
    "    country='us', # reviews from US\n",
    "    sort=Sort.NEWEST, # return newest reviews\n",
    "    count=200, # return 200 reviews\n",
    ")\n",
    "\n",
    "# If you pass `continuation_token` as an argument to the reviews function at this point,\n",
    "# it will crawl the items after 3 review items.\n",
    "\n",
    "time.sleep(0.1) # pause before next request\n",
    "\n",
    "result_scruff, _ = reviews(\n",
    "    'com.appspot.scruffapp',\n",
    "    continuation_token=continuation_token # avoids returning duplicate reviews\n",
    ")\n",
    "\n",
    "result_scruff_df = pd.DataFrame(result_scruff) # make into df\n",
    "result_scruff_df = result_scruff_df.drop(['reviewId', 'userImage', 'reviewCreatedVersion'], axis=1) # remove columns\n",
    "result_scruff_df['App'] = 'Scruff' # create new column with app name\n",
    "\n",
    "time.sleep(0.1) # pause before fetching app description\n",
    "\n",
    "# create a new column with description\n",
    "result_scruff_des = app(\n",
    "    'com.appspot.scruffapp',\n",
    "    lang='en', # defaults to 'en'\n",
    "    country='us' # defaults to 'us'\n",
    ")\n",
    "\n",
    "scruff_description = clean_text(result_scruff_des['description'])\n",
    "scruff_installs = result_scruff_des['realInstalls']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Taimi***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "result_taimi, continuation_token = reviews(\n",
    "    'com.takimi.android',\n",
    "    lang='en', # English reviews\n",
    "    country='us', # reviews from US\n",
    "    sort=Sort.NEWEST, # return newest reviews\n",
    "    count=200, # return 200 reviews\n",
    ")\n",
    "\n",
    "# If you pass `continuation_token` as an argument to the reviews function at this point,\n",
    "# it will crawl the items after 3 review items.\n",
    "\n",
    "time.sleep(0.1) # pause before next request\n",
    "\n",
    "result_taimi, _ = reviews(\n",
    "    'com.takimi.android',\n",
    "    continuation_token=continuation_token # avoids returning duplicate reviews\n",
    ")\n",
    "\n",
    "result_taimi_df = pd.DataFrame(result_taimi) # make into df\n",
    "result_taimi_df = result_taimi_df.drop(['reviewId', 'userImage', 'reviewCreatedVersion'], axis=1) # remove columns\n",
    "result_taimi_df['App'] = 'Taimi' # create new column with app name\n",
    "\n",
    "time.sleep(0.1) # pause before fetching app description\n",
    "\n",
    "# create a new column with description\n",
    "result_taimi_des = app(\n",
    "    'com.takimi.android',\n",
    "    lang='en', # defaults to 'en'\n",
    "    country='us' # defaults to 'us'\n",
    ")\n",
    "\n",
    "taimi_description = clean_text(result_taimi_des['description'])\n",
    "taimi_installs = result_taimi_des['realInstalls']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Millionaire Match***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "result_mil_match, continuation_token = reviews(\n",
    "    'com.millionairedating.millionairematch',\n",
    "    lang='en', # English reviews\n",
    "    country='us', # reviews from US\n",
    "    sort=Sort.NEWEST, # return newest reviews\n",
    "    count=200, # return 200 reviews\n",
    ")\n",
    "\n",
    "# If you pass `continuation_token` as an argument to the reviews function at this point,\n",
    "# it will crawl the items after 3 review items.\n",
    "\n",
    "time.sleep(0.1) # pause before next request\n",
    "\n",
    "result_mil_match, _ = reviews(\n",
    "    'com.millionairedating.millionairematch',\n",
    "    continuation_token=continuation_token # avoids returning duplicate reviews\n",
    ")\n",
    "\n",
    "result_mil_match_df = pd.DataFrame(result_mil_match) # make into df\n",
    "result_mil_match_df = result_mil_match_df.drop(['reviewId', 'userImage', 'reviewCreatedVersion'], axis=1) # remove columns\n",
    "result_mil_match_df['App'] = 'Millionaire Match' # create new column with app name\n",
    "\n",
    "time.sleep(0.1) # pause before fetching app description\n",
    "\n",
    "# create a new column with description\n",
    "result_mil_match_des = app(\n",
    "    'com.millionairedating.millionairematch',\n",
    "    lang='en', # defaults to 'en'\n",
    "    country='us' # defaults to 'us'\n",
    ")\n",
    "\n",
    "mil_match_description = clean_text(result_mil_match_des['description'])\n",
    "mil_match_installs = result_mil_match_des['realInstalls']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Luxy***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "result_luxy, continuation_token = reviews(\n",
    "    'com.luxy',\n",
    "    lang='en', # English reviews\n",
    "    country='us', # reviews from US\n",
    "    sort=Sort.NEWEST, # return newest reviews\n",
    "    count=200, # return 200 reviews\n",
    "    #filter_score_with=5 # we can filter for certain scores\n",
    ")\n",
    "\n",
    "# If you pass `continuation_token` as an argument to the reviews function at this point,\n",
    "# it will crawl the items after 3 review items.\n",
    "\n",
    "time.sleep(0.1) # pause before next request\n",
    "\n",
    "result_luxy, _ = reviews(\n",
    "    'com.luxy',\n",
    "    continuation_token=continuation_token # avoids returning duplicate reviews\n",
    ")\n",
    "\n",
    "result_luxy_df = pd.DataFrame(result_luxy)\n",
    "result_luxy_df = result_luxy_df.drop(['reviewId', 'userImage', 'reviewCreatedVersion'], axis=1) # remove columns\n",
    "result_luxy_df['App'] = 'Luxy' # create new column with app name\n",
    "\n",
    "time.sleep(0.1) # pause before fetching app description\n",
    "\n",
    "# create a new column with description\n",
    "result_luxy_des = app(\n",
    "    'com.luxy',\n",
    "    lang='en', # defaults to 'en'\n",
    "    country='us' # defaults to 'us'\n",
    ")\n",
    "\n",
    "\n",
    "luxy_description = clean_text(result_luxy_des['description'])\n",
    "luxy_installs = result_scruff_des['realInstalls']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***The League***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "result_league, continuation_token = reviews(\n",
    "    'com.league.theleague',\n",
    "    lang='en', # English reviews\n",
    "    country='us', # reviews from US\n",
    "    sort=Sort.NEWEST, # return newest reviews\n",
    "    count=200,\n",
    "    #filter_score_with=5 # we can filter for certain scores\n",
    ")\n",
    "\n",
    "# If you pass `continuation_token` as an argument to the reviews function at this point,\n",
    "# it will crawl the items after 3 review items.\n",
    "\n",
    "time.sleep(0.1) # pause before next request\n",
    "\n",
    "result_league, _ = reviews(\n",
    "    'com.league.theleague',\n",
    "    continuation_token=continuation_token # avoids returning duplicate reviews\n",
    ")\n",
    "\n",
    "result_league_df = pd.DataFrame(result_league)\n",
    "result_league_df = result_league_df.drop(['reviewId', 'userImage', 'reviewCreatedVersion'], axis=1) # remove columns\n",
    "result_league_df['App'] = 'League' # create new column with app name\n",
    "\n",
    "time.sleep(0.1) # pause before fetching app description\n",
    "\n",
    "# create a new column with description\n",
    "result_league_des = app(\n",
    "    'com.league.theleague',\n",
    "    lang='en', # defaults to 'en'\n",
    "    country='us' # defaults to 'us'\n",
    ")\n",
    "\n",
    "league_description = clean_text(result_league_des['description'])\n",
    "league_installs = result_league_des['realInstalls']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Christian Mingle***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "result_christian_mingle, continuation_token = reviews(\n",
    "    'com.spark.christianmingle',\n",
    "    lang='en', # English reviews\n",
    "    country='us', # reviews from US\n",
    "    sort=Sort.NEWEST, # return newest reviews\n",
    "    count=200,\n",
    "    #filter_score_with=5 # we can filter for certain scores\n",
    ")\n",
    "\n",
    "# If you pass `continuation_token` as an argument to the reviews function at this point,\n",
    "# it will crawl the items after 3 review items.\n",
    "\n",
    "time.sleep(0.1) # pause before next request\n",
    "\n",
    "result_christian_mingle, _ = reviews(\n",
    "    'com.spark.christianmingle',\n",
    "    continuation_token=continuation_token # avoids returning duplicate reviews\n",
    ")\n",
    "\n",
    "result_christian_mingle_df = pd.DataFrame(result_christian_mingle)\n",
    "result_christian_mingle_df = result_christian_mingle_df.drop(['reviewId', 'userImage', 'reviewCreatedVersion'], axis=1) # remove columns\n",
    "result_christian_mingle_df['App'] = 'Christian_Mingle' # create new column with app name\n",
    "\n",
    "time.sleep(0.1) # pause before fetching app description\n",
    "\n",
    "# create a new column with description\n",
    "result_christian_mingle_des = app(\n",
    "    'com.spark.christianmingle',\n",
    "    lang='en', # defaults to 'en'\n",
    "    country='us' # defaults to 'us'\n",
    ")\n",
    "\n",
    "chris_mingle_description = clean_text(result_christian_mingle_des['description'])\n",
    "chris_mingle_installs = result_christian_mingle_des['realInstalls']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Muzz***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "result_muzz, continuation_token = reviews(\n",
    "    'com.muzmatch.muzmatchapp',\n",
    "    lang='en', # English reviews\n",
    "    country='us', # reviews from US\n",
    "    sort=Sort.NEWEST, # return newest reviews\n",
    "    count=200,\n",
    "    #filter_score_with=5 # we can filter for certain scores\n",
    ")\n",
    "\n",
    "# If you pass `continuation_token` as an argument to the reviews function at this point,\n",
    "# it will crawl the items after 3 review items.\n",
    "\n",
    "time.sleep(0.1) # pause before fetching next request\n",
    "\n",
    "result_muzz, _ = reviews(\n",
    "    'com.muzmatch.muzmatchapp',\n",
    "    continuation_token=continuation_token # avoids returning duplicate reviews\n",
    ")\n",
    "\n",
    "result_muzz_df = pd.DataFrame(result_muzz)\n",
    "result_muzz_df = result_muzz_df.drop(['reviewId', 'userImage', 'reviewCreatedVersion'], axis=1) # remove columns\n",
    "result_muzz_df['App'] = 'Muzz' # create new column with app name\n",
    "\n",
    "time.sleep(0.1) # pause before fetching app description\n",
    "\n",
    "# create a new column with description\n",
    "result_muzz_des = app(\n",
    "    'com.muzmatch.muzmatchapp',\n",
    "    lang='en', # defaults to 'en'\n",
    "    country='us' # defaults to 'us'\n",
    ")\n",
    "\n",
    "muzz_description = clean_text(result_muzz_des['description'])\n",
    "muzz_installs = result_muzz_des['realInstalls']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Jswipe***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "result_jswipe, continuation_token = reviews(\n",
    "    'com.smooch.labs.jswipe',\n",
    "    lang='en', # English reviews\n",
    "    country='us', # reviews from US\n",
    "    sort=Sort.NEWEST, # return newest reviews\n",
    "    count=200,\n",
    "    #filter_score_with=5 # we can filter for certain scores\n",
    ")\n",
    "\n",
    "# If you pass `continuation_token` as an argument to the reviews function at this point,\n",
    "# it will crawl the items after 3 review items.\n",
    "\n",
    "time.sleep(0.1) # pause before next request\n",
    "\n",
    "result_jswipe, _ = reviews(\n",
    "    'com.smooch.labs.jswipe',\n",
    "    continuation_token=continuation_token # avoids returning duplicate reviews\n",
    ")\n",
    "\n",
    "result_jswipe_df = pd.DataFrame(result_jswipe)\n",
    "result_jswipe_df = result_jswipe_df.drop(['reviewId', 'userImage', 'reviewCreatedVersion'], axis=1) # remove columns\n",
    "result_jswipe_df['App'] = 'JSwipe' # create new column with app name\n",
    "\n",
    "time.sleep(0.1) # pause before fetching app description\n",
    "\n",
    "# create a new column with description\n",
    "result_jswipe_des = app(\n",
    "    'com.smooch.labs.jswipe',\n",
    "    lang='en', # defaults to 'en'\n",
    "    country='us' # defaults to 'us'\n",
    ")\n",
    "\n",
    "jswipe_description = clean_text(result_jswipe_des['description'])\n",
    "jswipe_installs = result_jswipe_des['realInstalls']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Mutual***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "result_mutual, continuation_token = reviews(\n",
    "    'com.mutualapp',\n",
    "    lang='en', # English reviews\n",
    "    country='us', # reviews from US\n",
    "    sort=Sort.NEWEST, # return newest reviews\n",
    "    count=200, #\n",
    "    #filter_score_with=5 # we can filter for certain scores\n",
    ")\n",
    "\n",
    "# If you pass `continuation_token` as an argument to the reviews function at this point,\n",
    "# it will crawl the items after 3 review items.\n",
    "\n",
    "time.sleep(0.1) # pause before next requset\n",
    "\n",
    "result_mutual, _ = reviews(\n",
    "    'com.mutualapp',\n",
    "    continuation_token=continuation_token # avoids returning duplicate reviews\n",
    ")\n",
    "\n",
    "result_mutual_df = pd.DataFrame(result_mutual)\n",
    "result_mutual_df = result_mutual_df.drop(['reviewId', 'userImage', 'reviewCreatedVersion'], axis=1) # remove columns\n",
    "result_mutual_df['App'] = 'Mutual' # create new column with app name\n",
    "\n",
    "time.sleep(0.1) # pause before fetching app description\n",
    "\n",
    "result_mutual_des = app(\n",
    "    'com.mutualapp',\n",
    "    lang='en', # defaults to 'en'\n",
    "    country='us' # defaults to 'us'\n",
    ")\n",
    "\n",
    "mutual_description = clean_text(result_mutual_des['description'])\n",
    "mutual_installs = result_mutual_des['realInstalls']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Senior Match***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "result_senior_match, continuation_token = reviews(\n",
    "    'com.successfulmatch.seniormatchdating',\n",
    "    lang='en', # English reviews\n",
    "    country='us', # reviews from US\n",
    "    sort=Sort.NEWEST, # return newest reviews\n",
    "    count=200,\n",
    "    #filter_score_with=5 # we can filter for certain scores\n",
    ")\n",
    "\n",
    "# If you pass `continuation_token` as an argument to the reviews function at this point,\n",
    "# it will crawl the items after 3 review items.\n",
    "\n",
    "time.sleep(0.1) # pause before next request\n",
    "\n",
    "result_senior_match, _ = reviews(\n",
    "    'com.successfulmatch.seniormatchdating',\n",
    "    continuation_token=continuation_token # avoids returning duplicate reviews\n",
    ")\n",
    "\n",
    "result_senior_match_df = pd.DataFrame(result_senior_match)\n",
    "result_senior_match_df = result_senior_match_df.drop(['reviewId', 'userImage', 'reviewCreatedVersion'], axis=1) # remove columns\n",
    "result_senior_match_df['App'] = 'Senior_Match' # create new column with app name\n",
    "\n",
    "time.sleep(0.1) # pause before fetching app description\n",
    "\n",
    "result_senior_match_des = app(\n",
    "    'com.successfulmatch.seniormatchdating',\n",
    "    lang='en', # defaults to 'en'\n",
    "    country='us' # defaults to 'us'\n",
    ")\n",
    "\n",
    "senior_match_description = clean_text(result_senior_match_des['description'])\n",
    "senior_match_installs = result_senior_match_des[\"realInstalls\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Ourtime***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "result_ourtime, continuation_token = reviews(\n",
    "    'com.peoplemedia.ourtime',\n",
    "    lang='en', # English reviews\n",
    "    country='us', # reviews from US\n",
    "    sort=Sort.NEWEST, # return newest reviews\n",
    "    count=200,\n",
    "    #filter_score_with=5 # we can filter for certain scores\n",
    ")\n",
    "\n",
    "# If you pass `continuation_token` as an argument to the reviews function at this point,\n",
    "# it will crawl the items after 3 review items.\n",
    "\n",
    "time.sleep(0.1) # pause before next request\n",
    "\n",
    "result_ourtime, _ = reviews(\n",
    "    'com.peoplemedia.ourtime',\n",
    "    continuation_token=continuation_token # avoids returning duplicate reviews\n",
    ")\n",
    "\n",
    "result_ourtime_df = pd.DataFrame(result_ourtime)\n",
    "result_ourtime_df = result_ourtime_df.drop(['reviewId', 'userImage', 'reviewCreatedVersion'], axis=1) # remove columns\n",
    "result_ourtime_df['App'] = 'Ourtime' # create new column with app name\n",
    "\n",
    "time.sleep(0.1) # pause before fetching app description\n",
    "\n",
    "result_ourtime_des = app(\n",
    "    'com.peoplemedia.ourtime',\n",
    "    lang='en', # defaults to 'en'\n",
    "    country='us' # defaults to 'us'\n",
    ")\n",
    "\n",
    "ourtime_description = clean_text(result_ourtime_des['description'])\n",
    "ourtime_installs = result_ourtime_des[\"realInstalls\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Dataframe Creation*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section compiles the scraped data from the different apps into two dataframes. The first dataframe \"App Marketing\" contains each apps description and number of downloads. The second dataframe \"App Reviews\" contains 200 user reviews from each dating app."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***App Marketing Dataframe***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "app_data = {\n",
    "    'App Name': ['Tinder',\n",
    "                 'Bumble',\n",
    "                 'Hinge',\n",
    "                 'HER',\n",
    "                 'Zoe',\n",
    "                 'Grindr',\n",
    "                 'SCRUFF',\n",
    "                 'Taimi',\n",
    "                 'Millionaire Match',\n",
    "                 'Luxy',\n",
    "                 'The League',\n",
    "                 'Christian Mingle',\n",
    "                 'Muzz',\n",
    "                 'Jswipe',\n",
    "                 'Mutual',\n",
    "                 'Senior Match',\n",
    "                 'Ourtime'],\n",
    "\n",
    "    'Description': [tinder_description,\n",
    "                    bumble_description,\n",
    "                    hinge_description,\n",
    "                    her_description,\n",
    "                    zoe_description,\n",
    "                    grindr_description,\n",
    "                    scruff_description,\n",
    "                    taimi_description,\n",
    "                    mil_match_description,\n",
    "                    luxy_description,\n",
    "                    league_description,\n",
    "                    chris_mingle_description,\n",
    "                    muzz_description,\n",
    "                    jswipe_description,\n",
    "                    mutual_description,\n",
    "                    senior_match_description,\n",
    "                    ourtime_description],\n",
    "\n",
    "    'Downloads': [tinder_installs,\n",
    "                  bumble_installs,\n",
    "                  hinge_installs,\n",
    "                  her_installs,\n",
    "                  zoe_installs,\n",
    "                  grindr_installs,\n",
    "                  scruff_installs,\n",
    "                  taimi_installs,\n",
    "                  mil_match_installs,\n",
    "                  luxy_installs,\n",
    "                  league_installs,\n",
    "                  chris_mingle_installs,\n",
    "                  muzz_installs,\n",
    "                  jswipe_installs,\n",
    "                  mutual_installs,\n",
    "                  senior_match_installs,\n",
    "                  ourtime_installs]\n",
    "}\n",
    "\n",
    "app_marketing_df = pd.DataFrame(app_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**App Reviews Dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "app_reviews_df = pd.concat([result_tinder_df,\n",
    "                            result_hinge_df,\n",
    "                            result_bumble_df,\n",
    "                            result_her_df,\n",
    "                            result_zoe_df,\n",
    "                            result_grindr_df,\n",
    "                            result_scruff_df,\n",
    "                            result_taimi_df,\n",
    "                            result_mil_match_df,\n",
    "                            result_luxy_df,\n",
    "                            result_league_df,\n",
    "                            result_christian_mingle_df,\n",
    "                            result_muzz_df,\n",
    "                            result_jswipe_df,\n",
    "                            result_mutual_df,\n",
    "                            result_senior_match_df,\n",
    "                            result_ourtime_df],\n",
    "                        ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "app_reviews_df.to_csv('app_reviews.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# grab only the first 6 reviews of each app for qualitative coding training dataset\n",
    "\n",
    "def first_n_each_app(df, column_name, n):\n",
    "    \"\"\"\n",
    "    Saves only the first n entries of each app in a DataFrame.\n",
    "    \"\"\"\n",
    "    return df.groupby(column_name).head(n)\n",
    "\n",
    "reviews_qual_coding_df = first_n_each_app(app_reviews_df, 'App', n=6)[['userName', 'content', 'App']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# save df as excel file\n",
    "reviews_qual_coding_df.to_excel(\"reviews_qual_coding_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See this [link](https://docs.google.com/document/d/1NhzBAHmDzahXzocFSfMaU2BbAGm5frJBv2Z1Ao64u9U/edit?usp=sharing) to supplemental materials for access to our training data + more information our coding scheme. See this [link](https://colab.research.google.com/drive/1rRJ8CcOaPDsrmtZ15cTgKrQ9u2lrqNyf?usp=sharing) for the code we used to train GPT on our coding scheme and then instruct GPT to analyze our review text data and conduct the qualitative coding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Data Analysis*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Cleaning**\n",
    "\n",
    "**NOTE 1:** We randomly selected 500 reviews and then trained GPT on our qualitative coding scheme to determine if each review contained a specific qualitative code (1) or didn't contain that code (0). Below, we uploaded the csv file of the dataframe containing information about if GPT determined if each qualitative code was present or not in each review. [Here](https://drive.google.com/file/d/1dKUAB1avzPZrwhm_2OsvV5U0GKsMovLT/view?usp=sharing) is a link to the csv file.\n",
    "\n",
    "**NOTE 2:** 'App type' and 'app genre' will be used interchangeably"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# load in the csv\n",
    "import pandas as pd\n",
    "\n",
    "coded_data = pd.read_csv('/content/app_reviews_coded_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# function to create word count\n",
    "\n",
    "def word_count(df, column_name, new_column_name='content_word_count'):\n",
    "    \"\"\"\n",
    "    Calculates the word count for each row in a specified column of a Pandas DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "        column_name (str): The name of the column containing text.\n",
    "        new_column_name (str, optional): The name for the new word count column. Defaults to 'word_count'.\n",
    "\n",
    "    Returns:\n",
    "         pd.DataFrame: The DataFrame with an added column containing word counts.\n",
    "    \"\"\"\n",
    "    df[new_column_name] = df[column_name].apply(lambda text: len(str(text).split()))\n",
    "    return df\n",
    "\n",
    "coded_data = word_count(coded_data, 'content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# rename christian mingle and senior match and jswipe\n",
    "coded_data['App'] = coded_data['App'].replace({'Christian_Mingle': 'Christian Mingle', 'Senior_Match': 'Senior Match'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# create aa column stating each dating app's genre\n",
    "\n",
    "# define mapping\n",
    "app_mapping = {\n",
    "\n",
    "    'Bumble': 'Mainstream',\n",
    "    'Tinder': 'Mainstream',\n",
    "    'Hinge': 'Mainstream',\n",
    "\n",
    "    'Taimi': 'Queer Co-Ed',\n",
    "    'Her': 'Queer Primarily Sapphic',\n",
    "    'Zoe': 'Queer Primarily Sapphic',\n",
    "    'Grindr': 'Queer Primarily Men',\n",
    "    'Scruff': 'Queer Primarily Men',\n",
    "\n",
    "    'Millionaire Match': 'Exclusive',\n",
    "    'Luxy': 'Exclusive',\n",
    "    'League': 'Exclusive',\n",
    "\n",
    "    'JSwipe': 'Religious',\n",
    "    'Mutual': 'Religious',\n",
    "    'Christian Mingle': 'Religious',\n",
    "    'Muzz': 'Religious',\n",
    "\n",
    "    'Ourtime': 'Seniors',\n",
    "    'Senior Match': 'Seniors'\n",
    "}\n",
    "\n",
    "# Create the new column using the map function\n",
    "coded_data['App_Type'] = coded_data['App'].map(app_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "coded_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "## save a dataframe of the positive sentiment reviews\n",
    "\n",
    "# boolean mask of only positive reviews\n",
    "coded_data_pos = coded_data[coded_data['pos_sent_gpt'] == 1]\n",
    "\n",
    "# save a dataframe of the total number of positive sentiment reviews for each app and app type\n",
    "coded_data_pos_apps = coded_data_pos[['App', 'App_Type']].value_counts().reset_index()\n",
    "coded_data_pos_apps.rename(columns={'count': 'pos_review_count'}, inplace=True)\n",
    "\n",
    "# save a dataframe of the total number of reviews for each app\n",
    "total_reviews = coded_data['App'].value_counts().reset_index()\n",
    "total_reviews.rename(columns = {'count': 'review_count'}, inplace=True)\n",
    "\n",
    "# merge the dataframes\n",
    "coded_data_pos_apps = coded_data_pos_apps.merge(total_reviews, on='App')\n",
    "\n",
    "# create a new column listing the proportion of positive sentiment reviews for each app and app type\n",
    "coded_data_pos_apps['prop'] = coded_data_pos_apps['pos_review_count']/coded_data_pos_apps['review_count']\n",
    "coded_data_pos_apps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "## save a dataframe of the negative sentiment reviews\n",
    "\n",
    "# boolean mask of only negative reviews\n",
    "coded_data_neg = coded_data[coded_data['neg_sent_gpt'] == 1]\n",
    "\n",
    "# save a dataframe of the total number of negative sentiment reviews for each app and app type\n",
    "coded_data_neg_apps = coded_data_neg[['App', 'App_Type']].value_counts().reset_index()\n",
    "coded_data_neg_apps.rename(columns={'count': 'neg_review_count'}, inplace=True)\n",
    "\n",
    "# save a dataframe of the total number of reviews for each app\n",
    "total_reviews = coded_data['App'].value_counts().reset_index()\n",
    "total_reviews.rename(columns = {'count': 'review_count'}, inplace=True)\n",
    "\n",
    "# merge the dataframes\n",
    "coded_data_neg_apps = coded_data_neg_apps.merge(total_reviews, on='App')\n",
    "\n",
    "# create a new column listing the proportion of negative sentiment reviews for each app and app type\n",
    "coded_data_neg_apps['prop'] = coded_data_neg_apps['neg_review_count']/coded_data_neg_apps['review_count']\n",
    "coded_data_neg_apps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "## create bar plot for proportion of reviews with negative sentiment reviews across apps\n",
    "import plotly.express as px\n",
    "\n",
    "# assign each dating app genre a color\n",
    "color_map = {'Mainstream': 'red',\n",
    "             'Queer Primarily Sapphic': 'pink',\n",
    "             'Queer Primarily Men': 'blue',\n",
    "             'Queer Co-Ed': 'purple',\n",
    "             'Exclusive': 'orange',\n",
    "             'Religious': 'green',\n",
    "             'Seniors': 'turquoise'}\n",
    "\n",
    "fig1 = px.bar(coded_data_neg_apps, x=\"App\", y=\"prop\", color=\"App_Type\",\n",
    "             title=\"Proportion of Reviews With Negative Sentiment Reviews Per App\",\n",
    "              # fix the order app genres appear in legend for easy comparison between plots\n",
    "             category_orders={'App_Type': ['Queer Primarily Sapphic', 'Queer Co-Ed', 'Exclusive', 'Religious', 'Seniors', 'Mainstream', 'Queer Prmarily Men']},\n",
    "             color_discrete_map=color_map,\n",
    "             labels = {'App': 'App Name', 'prop': 'Proportion of Reviews', 'App_Type': 'Dating App Genre'})\n",
    "\n",
    "# fix the order app names appear on x-axis for easy comparison between plots\n",
    "fig1.update_layout(xaxis={'categoryorder':'array',\n",
    "                         'categoryarray':['Zoe', 'Her', 'Taimi', 'Luxy', 'Millionaire Match', 'League', 'Christian Mingle', 'JSwipe', 'Mutual', 'Muzz', 'Ourtime', 'Senior Match', 'Tinder', 'Bumble', 'Hinge', 'Scruff', 'Grindr']})\n",
    "\n",
    "fig1.update_yaxes(range=[0, 1])\n",
    "\n",
    "fig1.show()\n",
    "\n",
    "## create bar plot for proportion of reviews with positive sentiment reviews across apps\n",
    "fig = px.bar(coded_data_pos_apps, x=\"App\", y=\"prop\", color=\"App_Type\",\n",
    "             color_discrete_map=color_map,\n",
    "             title=\"Proportion of Reviews With Positive Sentiment Reviews Per App\",\n",
    "                           # fix the order app genres appear in legend for easy comparison between plots\n",
    "             category_orders={'App_Type': ['Queer Primarily Sapphic', 'Queer Co-Ed', 'Exclusive', 'Religious', 'Seniors', 'Mainstream', 'Queer Prmarily Men']},\n",
    "             labels = {'App': 'App Name', 'prop': 'Proportion of Reviews', 'App_Type': 'Dating App Genre'})\n",
    "\n",
    "# fix the order app names appear on x-axis for easy comparison between plots\n",
    "fig.update_layout(xaxis={'categoryorder':'array',\n",
    "                         'categoryarray':['Zoe', 'Her', 'Taimi', 'Luxy', 'Millionaire Match', 'League', 'Christian Mingle', 'JSwipe', 'Mutual', 'Muzz', 'Ourtime', 'Senior Match', 'Tinder', 'Bumble', 'Hinge', 'Scruff', 'Grindr']})\n",
    "\n",
    "fig.update_yaxes(range=[0, 1])\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How much do people write when they love or hate an app?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "## create a line plot of the average word count for each rating\n",
    "\n",
    "# create a dataframe listing the average word count for each rating (# stars given)\n",
    "rating_wc_df = coded_data.groupby('score')['content_word_count'].mean().reset_index()\n",
    "\n",
    "# round every average word count by two decimal points for readibility\n",
    "rating_wc_df['average_word_count_rounded'] = rating_wc_df['content_word_count'].round(2)\n",
    "\n",
    "# create line plot\n",
    "fig = px.line(rating_wc_df, x=\"score\", y=\"content_word_count\",\n",
    "              text = 'average_word_count_rounded',\n",
    "              title='App Reviews Average Word Count Per Rating', markers = True)\n",
    "\n",
    "# position point labels in top right corner for readability\n",
    "fig.update_traces(textposition='top right')\n",
    "\n",
    "# remove decimal points on x axis\n",
    "fig.update_xaxes(tickmode='array', tickvals=[1, 2, 3, 4, 5])\n",
    "\n",
    "# label axes\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"Rating (# of Stars)\",\n",
    "    yaxis_title=\"Average Word Count\"\n",
    ")\n",
    "\n",
    "# adjust range on y-axis for readability\n",
    "fig.update_yaxes(range=[0, 37])\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "## create a line plot of the average word count for each rating per app type\n",
    "\n",
    "# create a dataframe listing the average word count for each rating for each app type\n",
    "rating_wc_app_df = coded_data.groupby(['App_Type', 'score'])['content_word_count'].mean().reset_index()\n",
    "\n",
    "# create line plot\n",
    "fig = px.line(rating_wc_app_df, x=\"score\", y=\"content_word_count\", color = \"App_Type\",\n",
    "              color_discrete_map=color_map,\n",
    "              title='App Reviews Average Word Count Per Rating', markers = True,\n",
    "              category_orders={'App_Type': ['Queer Primarily Sapphic', 'Queer Co-Ed', 'Exclusive', 'Religious', 'Seniors', 'Mainstream', 'Queer Prmarily Men']},\n",
    "              labels = {'App_Type': 'Dating App Genre'})\n",
    "\n",
    "# position point labels in top right corner for readability\n",
    "fig.update_traces(textposition='top right')\n",
    "\n",
    "# remove decimal points on x axis\n",
    "fig.update_xaxes(tickmode='array', tickvals=[1, 2, 3, 4, 5])\n",
    "\n",
    "# label axes\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"Rating (# of Stars)\",\n",
    "    yaxis_title=\"Average Word Count\"\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What topics do most people write about in their reviews?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "## create a dataframe containing info about each code and the frequency of each code\n",
    "\n",
    "# create a column containing the names of each code\n",
    "code_names = ['emojis', 'pos_ux', 'neg_ux', 'pos_ppl', 'neg_ppl', 'price', 'fraud', 'ban']\n",
    "\n",
    "# create a column containing a brief description of each code\n",
    "definitions = ['The review contains emojis',\n",
    "               'The review discusses positive user experience',\n",
    "               'The review discusses negative user experience',\n",
    "               'The review discusses positive social interactions with other app users',\n",
    "               'The review discusses negative social interactions with other app users',\n",
    "               'The review unhappy with monetization of the app',\n",
    "               'The review discusses encountering fraudulent accounts on the app',\n",
    "               'The review discusses getting their accounts banned']\n",
    "\n",
    "# calculate the frequency of each code\n",
    "prop_emojis = coded_data['emojis_gpt'].sum() / len(coded_data)\n",
    "prop_pos_ux = coded_data['pos_ux_gpt'].sum() / len(coded_data)\n",
    "prop_neg_ux = coded_data['neg_ux_gpt'].sum() / len(coded_data)\n",
    "prop_pos_ppl = coded_data['pos_ppl_gpt'].sum() / len(coded_data)\n",
    "prop_neg_ppl = coded_data['neg_ppl_gpt'].sum() / len(coded_data)\n",
    "prop_price = coded_data['price_gpt'].sum() / len(coded_data)\n",
    "prop_fraud = coded_data['fraud_gpt'].sum() / len(coded_data)\n",
    "prop_ban = coded_data['ban_gpt'].sum() / len(coded_data)\n",
    "\n",
    "# create a column containing the frequency of each code  (proportion of reviews that qualify for this code)\n",
    "proportions = [prop_emojis, prop_pos_ux, prop_neg_ux, prop_pos_ppl, prop_neg_ppl, prop_price, prop_fraud, prop_ban]\n",
    "\n",
    "# combine the columns together to create a dataframe\n",
    "coded_data_prop = pd.DataFrame({'Code': code_names, 'Code Definition': definitions, 'Proportion': proportions})\n",
    "coded_data_prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "## save a dataframe of reviews with price code\n",
    "\n",
    "# save a dataframe of the total number of reviews qualitfying for the price code for each app type\n",
    "coded_data_price = coded_data[coded_data['price_gpt'] == 1][['App_Type']].value_counts().reset_index()\n",
    "coded_data_price.rename(columns={'count': 'price_review_count'}, inplace=True)\n",
    "\n",
    "# save a dataframe of the total number of reviews for each app type\n",
    "total_type_reviews = coded_data['App_Type'].value_counts().reset_index()\n",
    "total_type_reviews.rename(columns = {'count': 'review_count'}, inplace=True)\n",
    "\n",
    "# merge the dataframes\n",
    "coded_data_price = coded_data_price.merge(total_type_reviews, on='App_Type')\n",
    "\n",
    "# create a new column listing the proportion of reviews qualifying for the price code for each app type\n",
    "coded_data_price['prop'] = coded_data_price['price_review_count']/coded_data_price['review_count']\n",
    "\n",
    "coded_data_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "## create bar plot for proportion of reviews qualifying for the price code across app genres\n",
    "\n",
    "# create bar plot\n",
    "fig = px.bar(coded_data_price, x=\"App_Type\", y=\"prop\", color=\"App_Type\", text_auto = \".2f\",\n",
    "             color_discrete_map=color_map,\n",
    "             title=\"Proportion of Reviews Unhappy With App Monetization\",\n",
    "             labels = {'App_Type': 'Dating App Genre', 'prop': 'Proportion of Reviews', 'App_Type': 'Dating App Genre'})\n",
    "\n",
    "# fix order app types appear on x axis for readability\n",
    "fig.update_layout(xaxis={'categoryorder':'array',\n",
    "                         'categoryarray':['Queer Primarily Sapphic', 'Queer Co-Ed', 'Exclusive', 'Religious', 'Seniors', 'Mainstream']})\n",
    "\n",
    "# remove legend to remove redundant information\n",
    "fig.update_layout(showlegend=False)\n",
    "\n",
    "# fix range on y axis for readability\n",
    "fig.update_yaxes(range=[0, 1])\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "## save a dataframe of reviews with negative people\n",
    "\n",
    "# save a dataframe of the total number of reviews qualitfying for the negative people  code for each app type\n",
    "coded_data_neg_ppl = coded_data[coded_data['neg_ppl_gpt'] == 1][['App_Type']].value_counts().reset_index()\n",
    "coded_data_neg_ppl.rename(columns={'count': 'neg_ppl_review_count'}, inplace=True)\n",
    "\n",
    "# save a dataframe of the total number of reviews for each app type\n",
    "total_type_reviews = coded_data['App_Type'].value_counts().reset_index()\n",
    "total_type_reviews.rename(columns = {'count': 'review_count'}, inplace=True)\n",
    "\n",
    "# merge the dataframes\n",
    "coded_data_neg_ppl = coded_data_neg_ppl.merge(total_type_reviews, on='App_Type')\n",
    "\n",
    "# create new column listing the proportion of reviews qualifying for the negative people code for each app type\n",
    "coded_data_neg_ppl['prop'] = coded_data_neg_ppl['neg_ppl_review_count']/coded_data_neg_ppl['review_count']\n",
    "\n",
    "coded_data_neg_ppl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "## create bar plot for proportion of reviews qualifying for the negative people code across app genres\n",
    "\n",
    "# create bar plot\n",
    "fig = px.bar(coded_data_neg_ppl, x=\"App_Type\", y=\"prop\", color=\"App_Type\", text_auto = \".2f\",\n",
    "             color_discrete_map=color_map,\n",
    "             title=\"Proportion of Reviews About Negative Social Interactions With People From App\",\n",
    "             labels = {'App_Type': 'Dating App Genre', 'prop': 'Proportion of Reviews', 'App_Type': 'Dating App Genre'})\n",
    "\n",
    "# fix order app types appear on x axis for readability\n",
    "fig.update_layout(xaxis={'categoryorder':'array',\n",
    "                         'categoryarray':['Queer Primarily Sapphic', 'Queer Co-Ed', 'Exclusive', 'Religious', 'Seniors', 'Mainstream']})\n",
    "\n",
    "# remove legend to remove redundant information\n",
    "fig.update_layout(showlegend=False)\n",
    "\n",
    "# fix range on y axis for readability\n",
    "fig.update_yaxes(range=[0, 1])\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Clustering Apps*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Description + Ad Spread Coding***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each app's marketing spread was manually coded using qualitative content analysis producing an excel spreadsheet. Here this dataframe is merged with the dataframe containing the apps description and number of downloads. The resulting dataframe will be used to do a KMeans clustering analysis to understand which apps might have most similar marketing styles.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code first cleans the dataframes in prepartion for the merge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ad_spreads_df = pd.read_csv(\"/content/ad_spreads_qual_coding_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "ad_spreads_df[\"# models smiling on title slide \"] = (ad_spreads_df[\"# models smiling on title slide \"] > 0).astype(int)\n",
    "ad_spreads_df[\"# models not smiling on title slide \"] = (ad_spreads_df[\"# models not smiling on title slide \"] > 0).astype(int)\n",
    "ad_spreads_df[\"# of white models on title slide\"] = (ad_spreads_df[\"# of white models on title slide\"] > 0).astype(int)\n",
    "ad_spreads_df[\"# of POC or racially ambiguous models on title slide\"] = (ad_spreads_df[\"# of POC or racially ambiguous models on title slide\"] > 0).astype(int)\n",
    "ad_spreads_df[\"# models fully clothed on title slide\"] = (ad_spreads_df[\"# models fully clothed on title slide\"] > 0).astype(int)\n",
    "ad_spreads_df[\"# models not fully clothed on title slide\"] = (ad_spreads_df[\"# models not fully clothed on title slide\"] > 0).astype(int)\n",
    "ad_spreads_df[\"App Name\"][6] = \"SCRUFF\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "app_des_ad_merge = ad_spreads_df.merge(app_marketing_df, on=\"App Name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "app_des_ad_merge.to_csv('app_des_ad_merge.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "text_feature = \"Description\"\n",
    "one_hot_features = [\n",
    "       'Bright Colors (does the color pallete look more neon, bright, loud? 1 = yes, 0 = no)',\n",
    "       'Muted Colors (does the color pallete look more softer and neutral? 1 = yes, 0 = no)',\n",
    "       'Lowercase (is the text all lowercase or mostly lowercase, such as starting with a capitalized letter and only lower case following it? 1 = yes, 0 = no)',\n",
    "       'Upper Case (is the text in all caps or mostly all caps? 1 = yes, 0 = no) ',\n",
    "       'Title Case (is the text using more formal capitalization, such as only capitalizing key words as one would do with an academic book title? 1 = yes, 0 = no)',\n",
    "       'Serifs (does the text used serifed font? 1 = yes, 0 = no)',\n",
    "       'Sans Serif (does the text use font without serifs? 1 = yes, 0 = no) ',\n",
    "       '# models smiling on title slide ',\n",
    "       '# models not smiling on title slide ',\n",
    "       '# of white models on title slide',\n",
    "       '# of POC or racially ambiguous models on title slide',\n",
    "       '# models fully clothed on title slide',\n",
    "       '# models not fully clothed on title slide']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "preprocessor = make_column_transformer(\n",
    "    (TfidfVectorizer(max_features=100), text_feature),\n",
    "    (StandardScaler(), one_hot_features),\n",
    "    remainder=\"drop\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here within-cluster sum of squared distances (inertia) was evaluated to determine the optimal number of clusters using the Elbow Method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "inertias = []\n",
    "\n",
    "for n_clusters in range(1, 17):\n",
    "    des_ad_pipeline = make_pipeline(\n",
    "        preprocessor,\n",
    "        KMeans(n_clusters=n_clusters, random_state=112)\n",
    "    )\n",
    "    des_ad_pipeline.fit(app_des_ad_merge)\n",
    "\n",
    "    kmeans = des_ad_pipeline.named_steps[\"kmeans\"]\n",
    "    inertias.append(kmeans.inertia_)\n",
    "\n",
    "# Plot the elbow method graph\n",
    "plt.figure(figsize=(17, 6))\n",
    "plt.plot(range(1, 17), inertias, marker='o')\n",
    "plt.title('Optimal Number of Clusters (Using Elbow Method)')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Inertia')\n",
    "plt.xticks(range(1, 17))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The elbow graph shows that 4 is the optimal number of clusters for our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "des_ad_pipeline = make_pipeline(\n",
    "    preprocessor,\n",
    "    KMeans(n_clusters=4, random_state=42)\n",
    ")\n",
    "\n",
    "des_ad_pipeline.fit(app_des_ad_merge)\n",
    "des_ad_model = des_ad_pipeline.named_steps[\"kmeans\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following print outs show the different cluster groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "for doc in app_des_ad_merge[\"App Name\"][des_ad_model.labels_ == 0]:\n",
    "  print(doc)\n",
    "  print(\"--------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "for doc in app_des_ad_merge[\"App Name\"][des_ad_model.labels_ == 1]:\n",
    "  print(doc)\n",
    "  print(\"--------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "for doc in app_des_ad_merge[\"App Name\"][des_ad_model.labels_ == 2]:\n",
    "  print(doc)\n",
    "  print(\"--------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "for doc in app_des_ad_merge[\"App Name\"][des_ad_model.labels_ == 3]:\n",
    "  print(doc)\n",
    "  print(\"--------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We chose a heatmap to visualize the presence of different features in different clusters. The following code cleans the dataframes and produces a heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "app_des_ad_merge['Bright Colors (1 = yes, 0 = no)'] = app_des_ad_merge['Bright Colors (does the color pallete look more neon, bright, loud? 1 = yes, 0 = no)']\n",
    "app_des_ad_merge['Muted Colors (1 = yes, 0 = no)'] = app_des_ad_merge['Muted Colors (does the color pallete look more softer and neutral? 1 = yes, 0 = no)']\n",
    "app_des_ad_merge['Lowercase (1 = yes, 0 = no)'] = app_des_ad_merge['Lowercase (is the text all lowercase or mostly lowercase, such as starting with a capitalized letter and only lower case following it? 1 = yes, 0 = no)']\n",
    "app_des_ad_merge['Upper Case (1 = yes, 0 = no)'] = app_des_ad_merge['Upper Case (is the text in all caps or mostly all caps? 1 = yes, 0 = no) ']\n",
    "app_des_ad_merge['Title Case (1 = yes, 0 = no)'] = app_des_ad_merge['Title Case (is the text using more formal capitalization, such as only capitalizing key words as one would do with an academic book title? 1 = yes, 0 = no)']\n",
    "app_des_ad_merge['Serifs (1 = yes, 0 = no)'] = app_des_ad_merge['Serifs (does the text used serifed font? 1 = yes, 0 = no)']\n",
    "app_des_ad_merge['Sans Serif (1 = yes, 0 = no)'] = app_des_ad_merge['Sans Serif (does the text use font without serifs? 1 = yes, 0 = no) ']\n",
    "app_des_ad_merge['Contains models smiling (1 = yes, 0 = no)'] = app_des_ad_merge['# models smiling on title slide ']\n",
    "app_des_ad_merge['Contains models not smiling (1 = yes, 0 = no)'] = app_des_ad_merge['# models not smiling on title slide ']\n",
    "app_des_ad_merge['Contains white models (1 = yes, 0 = no)'] = app_des_ad_merge['# of white models on title slide']\n",
    "app_des_ad_merge['Contains POC or racially ambiguous models (1 = yes, 0 = no)'] = app_des_ad_merge['# of POC or racially ambiguous models on title slide']\n",
    "app_des_ad_merge['Contains fully clothed models (1 = yes, 0 = no)'] = app_des_ad_merge['# models fully clothed on title slide']\n",
    "app_des_ad_merge['Contains not fully clothed models (1 = yes, 0 = no)'] = app_des_ad_merge['# models not fully clothed on title slide']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "app_des_ad_merge.drop(\n",
    "    columns=['Downloads',\n",
    "             'Bright Colors (does the color pallete look more neon, bright, loud? 1 = yes, 0 = no)',\n",
    "             'Muted Colors (does the color pallete look more softer and neutral? 1 = yes, 0 = no)',\n",
    "             'Lowercase (is the text all lowercase or mostly lowercase, such as starting with a capitalized letter and only lower case following it? 1 = yes, 0 = no)',\n",
    "             'Upper Case (is the text in all caps or mostly all caps? 1 = yes, 0 = no) ',\n",
    "             'Title Case (is the text using more formal capitalization, such as only capitalizing key words as one would do with an academic book title? 1 = yes, 0 = no)',\n",
    "             'Serifs (does the text used serifed font? 1 = yes, 0 = no)',\n",
    "             'Sans Serif (does the text use font without serifs? 1 = yes, 0 = no) ',\n",
    "             '# models smiling on title slide ',\n",
    "             '# models not smiling on title slide ',\n",
    "             '# of white models on title slide',\n",
    "             '# of POC or racially ambiguous models on title slide',\n",
    "             '# models fully clothed on title slide',\n",
    "             '# models not fully clothed on title slide'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Manually assign clusters\n",
    "cluster_mapping = {\n",
    "    \"Grindr\": 1, \"SCRUFF\": 1,\n",
    "    \"Tinder\": 2, \"Bumble\": 2, \"HER\": 2, \"Zoe\": 2, \"Taimi\": 2, \"Christian Mingle\": 2, \"Muzz\": 2, \"Jswipe\": 2, \"Mutual\": 2, \"Ourtime\": 2,\n",
    "    \"Hinge\": 3,\n",
    "    \"Millionaire Match\": 4, \"Luxy\": 4, \"The League\": 4, \"Senior Match\": 4\n",
    "}\n",
    "\n",
    "app_des_ad_merge[\"Cluster\"] = app_des_ad_merge[\"App Name\"].map(cluster_mapping)\n",
    "app_des_ad_merge = app_des_ad_merge.dropna(subset=[\"Cluster\"])  # Remove rows without assigned clusters\n",
    "app_des_ad_merge[\"Cluster\"] = app_des_ad_merge[\"Cluster\"].astype(int)\n",
    "\n",
    "# Group by cluster and calculate mean values\n",
    "cluster_means = app_des_ad_merge.groupby(\"Cluster\").mean(numeric_only=True)\n",
    "\n",
    "# Transpose the dataframe so that clusters are on the x-axis and features are on the y-axis\n",
    "plt.figure(figsize=(10, 8))  # Adjust figure size for better readability\n",
    "sns.heatmap(cluster_means.T, annot=True, cmap=\"coolwarm\", linewidths=0.5)\n",
    "\n",
    "plt.title(\"Feature Averages by Cluster\", fontsize=14)\n",
    "plt.xlabel(\"Cluster\", fontsize=12)\n",
    "plt.ylabel(\"Feature\", fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
